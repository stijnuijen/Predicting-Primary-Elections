{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "# Extra Features for a boost in Model Perfomance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By GROUP4: Stijn Uijen, Leon van Veldhuijzen and Max van Splunteren.\n",
    "\n",
    "\n",
    "The code in this file belongs to the second part of the group assignment. Here, we will try to boost \n",
    "performance for each of the classification models by adding extra features we think could be relevant to the county data.\n",
    "\n",
    "In the first part, the extra features are added, in the second part the code is the same as in part one for each of the classification problems, and in the last part the models get retrained with the new data.\n",
    "\n",
    "#### So the only new code is the 'Add the new features to the county_data' and 'New Models' part.\n",
    " \n",
    "\n",
    "#### Acknowledgements\n",
    "Parts of the code here were inspired by lectures and materials from Dr. Stevan Rudinac and Rens Dimmendaal\n",
    "and the book 'Introduction to Machine Learning with Python' by A. C. Muller and S. Guido. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "county = 'county_facts.csv'\n",
    "\n",
    "results = 'primary_results.csv'\n",
    "\n",
    "county_data = pd.read_csv(county)\n",
    "\n",
    "results_data = pd.read_csv(results)\n",
    "\n",
    "\n",
    "##### extra features data-sets\n",
    "extra_county_data = pd.read_excel('international_migrants.xlsx')\n",
    "edu_data = pd.read_excel('education_counties.xlsx')\n",
    "unem_data = pd.read_excel('county_unemployment.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### filter for results for Democrats and Republicans \n",
    "republican_results = results_data[results_data['party'].isin(['Republican'])]\n",
    "\n",
    "democrat_results = results_data[results_data['party'].isin(['Democrat'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop all 'whole' state rows and the USA row by checking if 'state_abbreviation' == NaN\n",
    "\n",
    "# first make a list with indexes of the rows that have to be deleted \n",
    "indexes = []\n",
    "\n",
    "index = 0 \n",
    "\n",
    "for index, row in county_data.iterrows():\n",
    "    \n",
    "    if pd.isnull(row['state_abbreviation']):\n",
    "        \n",
    "        indexes.append(index)\n",
    "        \n",
    "    index += 1\n",
    "\n",
    "# now drop these rows by index\n",
    "county_data = county_data.drop(county_data.index[indexes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add the new features to the county_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now add the new features to the democratic data-set\n",
    "\n",
    "mig_rate_2011 = pd.DataFrame(data = {'R_INTERNATIONAL_MIG_2011' : [0] * len(county_data['fips'])})\n",
    "mig_rate_2012 = pd.DataFrame(data = {'R_INTERNATIONAL_MIG_2012' : [0] * len(county_data['fips'])})\n",
    "mig_rate_2013 = pd.DataFrame(data = {'R_INTERNATIONAL_MIG_2013' : [0] * len(county_data['fips'])})\n",
    "mig_rate_2014 = pd.DataFrame(data = {'R_INTERNATIONAL_MIG_2014' : [0] * len(county_data['fips'])})\n",
    "mig_rate_2015 = pd.DataFrame(data = {'R_INTERNATIONAL_MIG_2015' : [0] * len(county_data['fips'])})\n",
    "mig_rate_2016 = pd.DataFrame(data = {'R_INTERNATIONAL_MIG_2016' : [0] * len(county_data['fips'])})\n",
    "\n",
    "less_than_highschool_2011_2015 = pd.DataFrame(data = {'less_than_highschool_2011_2015' : [0] * len(county_data['fips'])})\n",
    "#only_highschool_2011_2015 = pd.DataFrame(data = {'only_highschool_2011_2015' : [0] * len(county_data['fips'])})\n",
    "# college_degree_2011_2015 = pd.DataFrame(data = {'college_degree_2011_2015' : [0] * len(county_data['fips'])})\n",
    "# bachelor_or_higher_2011_2015 = pd.DataFrame(data = {'bachelor_or_higher_2011_2015' : [0] * len(county_data['fips'])})\n",
    "\n",
    "Unemployment_rate_2016 = pd.DataFrame(data = {'Unemployment_rate_2016' : [0] * len(county_data['fips'])})\n",
    "Median_Household_Income_2015 = pd.DataFrame(data = {'Median_Household_Income_2015' : [0] * len(county_data['fips'])})\n",
    "Med_HH_Income_Percent_of_State_Total_2015 = \\\n",
    "                pd.DataFrame(data = {'Med_HH_Income_Percent_of_State_Total_2015' : [0] * len(county_data['fips'])})\n",
    "\n",
    "\n",
    "data_plus = pd.concat([county_data ,mig_rate_2011, mig_rate_2012, mig_rate_2013, \n",
    "                             mig_rate_2014, mig_rate_2015, mig_rate_2016,\n",
    "                             less_than_highschool_2011_2015, \n",
    "                             Unemployment_rate_2016, Median_Household_Income_2015,\n",
    "                             Med_HH_Income_Percent_of_State_Total_2015], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create dictionaries for the extra variables where the counties are keys and the corresponing value \n",
    "# from the feature as the value.\n",
    "\n",
    "int_mig_dict = {}\n",
    "int_mig_dict_fips_missing = {}\n",
    "\n",
    "edu_dict = {}\n",
    "edu_dict_fips_missing = {}\n",
    "\n",
    "unem_dict = {}\n",
    "unem_dict_fips_missing = {}\n",
    "\n",
    "for index, row in extra_county_data.iterrows():\n",
    "    \n",
    "        int_mig_dict[row['FIPS']] = {'R_INTERNATIONAL_MIG_2011': extra_county_data['R_INTERNATIONAL_MIG_2011'][index],\n",
    "                                 'R_INTERNATIONAL_MIG_2012': extra_county_data['R_INTERNATIONAL_MIG_2012'][index],\n",
    "                                 'R_INTERNATIONAL_MIG_2013': extra_county_data['R_INTERNATIONAL_MIG_2013'][index],\n",
    "                                 'R_INTERNATIONAL_MIG_2014': extra_county_data['R_INTERNATIONAL_MIG_2014'][index],\n",
    "                                 'R_INTERNATIONAL_MIG_2015': extra_county_data['R_INTERNATIONAL_MIG_2015'][index], \n",
    "                                 'R_INTERNATIONAL_MIG_2016': extra_county_data['R_INTERNATIONAL_MIG_2016'][index]}\n",
    "        \n",
    "        int_mig_dict_fips_missing[row['Area_Name']] = \\\n",
    "                            {'R_INTERNATIONAL_MIG_2011': extra_county_data['R_INTERNATIONAL_MIG_2011'][index],\n",
    "                                 'R_INTERNATIONAL_MIG_2012': extra_county_data['R_INTERNATIONAL_MIG_2012'][index],\n",
    "                                 'R_INTERNATIONAL_MIG_2013': extra_county_data['R_INTERNATIONAL_MIG_2013'][index],\n",
    "                                 'R_INTERNATIONAL_MIG_2014': extra_county_data['R_INTERNATIONAL_MIG_2014'][index],\n",
    "                                 'R_INTERNATIONAL_MIG_2015': extra_county_data['R_INTERNATIONAL_MIG_2015'][index], \n",
    "                                 'R_INTERNATIONAL_MIG_2016': extra_county_data['R_INTERNATIONAL_MIG_2016'][index]}\n",
    "\n",
    "        edu_dict[row['FIPS']] = {'less_than_highschool_2011_2015':\\\n",
    "                                 edu_data['Percent of adults with less than a high school diploma, 2011-2015'][index]}\n",
    "                                 \n",
    "        edu_dict_fips_missing[row['Area_Name']] = {'less_than_highschool_2011_2015': \\\n",
    "                                edu_data['Percent of adults with less than a high school diploma, 2011-2015'][index]}\n",
    "        \n",
    "        unem_dict[row['FIPS']] = {'Unemployment_rate_2016': unem_data['Unemployment_rate_2016'][index],\n",
    "                                 'Median_Household_Income_2015': unem_data['Median_Household_Income_2015'][index],\n",
    "                                 'Med_HH_Income_Percent_of_State_Total_2015': \\\n",
    "                                  unem_data[\"Med_HH_Income_Percent_of_State_Total_2015\"][index]}\n",
    "                                 \n",
    "        unem_dict_fips_missing[row['Area_Name']] = {'Unemployment_rate_2016': unem_data['Unemployment_rate_2016'][index],\n",
    "                                 'Median_Household_Income_2015': unem_data['Median_Household_Income_2015'][index],\n",
    "                                 'Med_HH_Income_Percent_of_State_Total_2015': \\\n",
    "                                                    unem_data[\"Med_HH_Income_Percent_of_State_Total_2015\"][index]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill values for migrant features \n",
    "for index, row in data_plus.iterrows():\n",
    "    \n",
    "    if pd.isnull(row['fips']) and row['area_name'] in int_mig_dict_fips_missing: \n",
    "        \n",
    "        data_plus.loc[index, 'R_INTERNATIONAL_MIG_2011'] = \\\n",
    "        int_mig_dict_fips_missing[row['area_name']]['R_INTERNATIONAL_MIG_2011']\n",
    "        data_plus.loc[index, 'R_INTERNATIONAL_MIG_2012'] = \\\n",
    "        int_mig_dict_fips_missing[row['area_name']]['R_INTERNATIONAL_MIG_2012']\n",
    "        data_plus.loc[index, 'R_INTERNATIONAL_MIG_2013'] = \\\n",
    "        int_mig_dict_fips_missing[row['area_name']]['R_INTERNATIONAL_MIG_2013']\n",
    "        data_plus.loc[index, 'R_INTERNATIONAL_MIG_2014'] = \\\n",
    "        int_mig_dict_fips_missing[row['area_name']]['R_INTERNATIONAL_MIG_2014']\n",
    "        data_plus.loc[index, 'R_INTERNATIONAL_MIG_2015'] = \\\n",
    "        int_mig_dict_fips_missing[row['area_name']]['R_INTERNATIONAL_MIG_2015']\n",
    "        data_plus.loc[index, 'R_INTERNATIONAL_MIG_2016'] = \\\n",
    "        int_mig_dict_fips_missing[row['area_name']]['R_INTERNATIONAL_MIG_2016']\n",
    "        \n",
    "    elif row['fips'] in int_mig_dict:\n",
    "        data_plus.loc[index, 'R_INTERNATIONAL_MIG_2011'] = int_mig_dict[row['fips']]['R_INTERNATIONAL_MIG_2011']\n",
    "        data_plus.loc[index, 'R_INTERNATIONAL_MIG_2012'] = int_mig_dict[row['fips']]['R_INTERNATIONAL_MIG_2012']\n",
    "        data_plus.loc[index, 'R_INTERNATIONAL_MIG_2013'] = int_mig_dict[row['fips']]['R_INTERNATIONAL_MIG_2013']\n",
    "        data_plus.loc[index, 'R_INTERNATIONAL_MIG_2014'] = int_mig_dict[row['fips']]['R_INTERNATIONAL_MIG_2014']\n",
    "        data_plus.loc[index, 'R_INTERNATIONAL_MIG_2015'] = int_mig_dict[row['fips']]['R_INTERNATIONAL_MIG_2015']\n",
    "        data_plus.loc[index, 'R_INTERNATIONAL_MIG_2016'] = int_mig_dict[row['fips']]['R_INTERNATIONAL_MIG_2016']\n",
    "        \n",
    "# fill values for education features \n",
    "for index, row in data_plus.iterrows():\n",
    "    \n",
    "    if pd.isnull(row['fips']) and row['area_name'] in edu_dict_fips_missing: \n",
    "        \n",
    "        data_plus.loc[index, 'less_than_highschool_2011_2015'] = \\\n",
    "        edu_dict_fips_missing[row['area_name']]['less_than_highschool_2011_2015']\n",
    "\n",
    "        \n",
    "    elif row['fips'] in edu_dict:\n",
    "        data_plus.loc[index, 'less_than_highschool_2011_2015'] = \\\n",
    "        edu_dict[row['fips']]['less_than_highschool_2011_2015']\n",
    "\n",
    "# fill values for unemployment features \n",
    "for index, row in data_plus.iterrows():\n",
    "    \n",
    "    if pd.isnull(row['fips']) and row['area_name'] in unem_dict_fips_missing: \n",
    "        \n",
    "        data_plus.loc[index, 'Unemployment_rate_2016'] = \\\n",
    "        unem_dict_fips_missing[row['area_name']]['Unemployment_rate_2016']\n",
    "        data_plus.loc[index, 'Median_Household_Income_2015'] = \\\n",
    "        unem_dict_fips_missing[row['area_name']]['Median_Household_Income_2015']\n",
    "        data_plus.loc[index, 'Med_HH_Income_Percent_of_State_Total_2015'] = \\\n",
    "        unem_dict_fips_missing[row['area_name']]['Med_HH_Income_Percent_of_State_Total_2015']\n",
    "        \n",
    "        \n",
    "    elif row['fips'] in unem_dict:\n",
    "        data_plus.loc[index, 'Unemployment_rate_2016'] = unem_dict[row['fips']]['Unemployment_rate_2016']\n",
    "        data_plus.loc[index, 'Median_Household_Income_2015'] = \\\n",
    "            unem_dict[row['fips']]['Median_Household_Income_2015']\n",
    "        data_plus.loc[index, 'Med_HH_Income_Percent_of_State_Total_2015'] = \\\n",
    "            unem_dict[row['fips']]['Med_HH_Income_Percent_of_State_Total_2015']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop rows with missing values\n",
    "county_data = data_plus.dropna(axis=0, how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\development\\anaconda\\lib\\site-packages\\pandas\\core\\frame.py:2844: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# rename column names\n",
    "county_data.rename(index=str, columns={\n",
    "'PST045214':\"Population: 2014 estimate\",\n",
    "'PST040210':\"Population: 2010 (April 1) estimates base\",\n",
    "'PST120214':\"Population: percent change - April 1: 2010 to July 1: 2014\",\n",
    "'POP010210':\"Population: 2010\",\n",
    "'AGE135214':\"Persons under 5 years: percent: 2014\",\n",
    "'AGE295214':\"Persons under 18 years: percent: 2014\",\n",
    "'AGE775214':\"Persons 65 years and over: percent: 2014\",\n",
    "'SEX255214':\"Female persons: percent: 2014\",\n",
    "'RHI125214':\"White alone: percent: 2014\",\n",
    "'RHI225214':\"Black or African American alone: percent: 2014\",\n",
    "'RHI325214':\"American Indian and Alaska Native alone: percent: 2014\",\n",
    "'RHI425214':\"Asian alone: percent: 2014\",\n",
    "'RHI525214':\"Native Hawaiian and Other Pacific Islander alone: percent: 2014\",\n",
    "'RHI625214':\"Two or More Races: percent: 2014\",\n",
    "'RHI725214':\"Hispanic or Latino: percent: 2014\",\n",
    "'HI825214':\"White alone: not Hispanic or Latino: percent: 2014\",\n",
    "'POP715213':\"Living in same house 1 year & over: percent: 2009-2013\",\n",
    "'POP645213':\"Foreign born persons: percent: 2009-2013\",\n",
    "'POP815213':\"Language other than English spoken at home: pct age 5+: 2009-2013\",\n",
    "'EDU635213':\"High school graduate or higher: percent of persons age 25+: 2009-2013\",\n",
    "'EDU685213':\"Bachelor's degree or higher: percent of persons age 25+: 2009-2013\",\n",
    "'VET605213':\"Veterans: 2009-2013\",\n",
    "'LFE305213':\"Mean travel time to work (minutes): workers age 16+: 2009-2013\",\n",
    "'HSG010214':\"Housing units: 2014\",\n",
    "'HSG445213':\"Homeownership rate: 2009-2013\",\n",
    "'HSG096213':\"Housing units in multi-unit structures: percent: 2009-2013\",\n",
    "'HSG495213':\"Median value of owner-occupied housing units: 2009-2013\",\n",
    "'HSD410213':\"Households: 2009-2013\",\n",
    "'HSD310213':\"Persons per household: 2009-2013\",\n",
    "'INC910213':\"Per capita money income in past 12 months (2013 dollars): 2009-2013\",\n",
    "'INC110213':\"Median household income: 2009-2013\",\n",
    "'PVY020213':\"Persons below poverty level: percent: 2009-2013\",\n",
    "'BZA010213':\"Private nonfarm establishments: 2013\",\n",
    "'BZA110213':\"Private nonfarm employment:  2013\",\n",
    "'BZA115213':\"Private nonfarm employment: percent change: 2012-2013\",\n",
    "'NES010213':\"Nonemployer establishments: 2013\",\n",
    "'SBO001207':\"Total number of firms: 2007\",\n",
    "'SBO315207':\"Black-owned firms: percent: 2007\",\n",
    "'SBO115207':\"American Indian- and Alaska Native-owned firms: percent: 2007\",\n",
    "'SBO215207':\"Asian-owned firms: percent: 2007\",\n",
    "'SBO515207':\"Native Hawaiian- and Other Pacific Islander-owned firms: percent: 2007\",\n",
    "'SBO415207':\"Hispanic-owned firms: percent: 2007\",\n",
    "'SBO015207':\"Women-owned firms: percent: 2007\",\n",
    "'MAN450207':\"Manufacturers shipments: 2007 ($1:000)\",\n",
    "'WTN220207':\"Merchant wholesaler sales: 2007 ($1:000)\",\n",
    "'RTN130207':\"Retail sales: 2007 ($1:000)\",\n",
    "'RTN131207':\"Retail sales per capita: 2007\",\n",
    "'AFN120207':\"Accommodation and food services sales: 2007 ($1:000)\",\n",
    "'BPS030214':\"Building permits: 2014\",\n",
    "'LND110210':\"Land area in square miles: 2010\",\n",
    "'POP060210':\"Population per square mile: 2010\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Democrats train/ test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\development\\anaconda\\lib\\site-packages\\pandas\\core\\indexes\\api.py:77: RuntimeWarning: '<' not supported between instances of 'str' and 'int', sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary with fips as keys and winner as value. Use to later acces the winner per row of the county data.\n",
    "# (fips are the unique county codes)\n",
    "dem_winners = {}\n",
    "dem_winners_fips_missing = {}\n",
    "\n",
    "for index, row in democrat_results.iterrows():\n",
    "    \n",
    "    # some county fips are missing, add to seperate dict to link them to the winner\n",
    "    if pd.isnull(row['fips']) and row['candidate'] == 'Hillary Clinton':\n",
    "        \n",
    "        dem_winners_fips_missing[row['county']] = [row['state_abbreviation'], row['fraction_votes'],\n",
    "                                                   'Hillary Clinton']\n",
    "        \n",
    "    elif row['candidate'] == 'Hillary Clinton':\n",
    "        \n",
    "        dem_winners[row['fips']] = ['Hillary Clinton', row['fraction_votes']]\n",
    "                \n",
    "for index, row in democrat_results.iterrows():\n",
    "    \n",
    "    if pd.isnull(row['fips']) and row['candidate'] == 'Bernie Sanders':\n",
    "        \n",
    "        if row['fraction_votes'] > dem_winners_fips_missing[row['county']][1]:\n",
    "             \n",
    "                dem_winners_fips_missing[row['county']] = [row['state_abbreviation'],\n",
    "                                                        row['fraction_votes'], 'Bernie Sander']\n",
    "        \n",
    "        elif row['fraction_votes'] == dem_winners_fips_missing[row['county']][1]:\n",
    "             \n",
    "                dem_winners_fips_missing[row['county']] = [row['state_abbreviation'],'Tie']\n",
    "    \n",
    "    \n",
    "    elif row['candidate'] == 'Bernie Sanders' and row['fraction_votes'] > dem_winners[row['fips']][1]:\n",
    "        \n",
    "        dem_winners[row['fips']][0] = 'Bernie Sanders'\n",
    "        \n",
    "    \n",
    "    elif row['candidate'] == 'Bernie Sanders' and row['fraction_votes'] == dem_winners[row['fips']][1]:\n",
    "        \n",
    "        dem_winners[row['fips']][0] = 'Tie'\n",
    "\n",
    "\n",
    "# create the y column: 'democratic_winner'. Set values to 0 for now. Merge with the county data.        \n",
    "democratic_winner = {'democratic_winner' : [0] * len(county_data['fips'])}\n",
    "\n",
    "democratic_winner_df = pd.DataFrame(data = democratic_winner)\n",
    "\n",
    "democratic_data = pd.concat([county_data ,democratic_winner_df], axis = 1)\n",
    "\n",
    "\n",
    "# Now set the values of the 'democratic_winner' column to the either Bernie, Hillary or Tie. Value stays 0 if \n",
    "# the county code is not in the result data-set, and therefore missing\n",
    "for index, row in democratic_data.iterrows():\n",
    "    \n",
    "    # this is the if statement for where country fip is missing and berny is thus the winner. \n",
    "    if pd.isnull(row['fips']): \n",
    "        if row['area_name'] in dem_winners_fips_missing:\n",
    "            democratic_data.loc[index, 'democratic_winner'] = 'Bernie Sanders'\n",
    "    \n",
    "    # otherwise look in the winner dict to see who was the winner\n",
    "    elif row['fips'] in dem_winners:\n",
    "        democratic_data.loc[index, 'democratic_winner'] = dem_winners[row['fips']][0]\n",
    "    \n",
    "    \n",
    "# remove all the rows where the y variable is missing : value 0\n",
    "\n",
    "# this means that also the tie rows are dropped:\n",
    "democratic_data_clean = democratic_data[democratic_data['democratic_winner'].isin \\\n",
    "                                        (['Hillary Clinton', 'Bernie Sanders'])]\n",
    "\n",
    "# threshold for dropping row due to missing values is 55 (all features) - 1 (y variable) = 54\n",
    "democratic_data_clean = democratic_data_clean.dropna(axis=0, thresh = 54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create train/test split \n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# states for the test split where elections where after april 19 (makes about 30% of total population and 22% of rows): \n",
    "# Indiana, West Virginia, Oregon, California, Montana, New Jersey, New Mexico, North Dakota, South Dakota,\n",
    "# Pennsylvania, Rhode Island, Connecticut, Delaware, Kentucky, and Maryland. \n",
    "# (See drive for ordering by date) \n",
    "# NB: nebraska is in the republican cutoff and not the democratic. And Kentucky not in the Republican \n",
    "# but is in the democratic.\n",
    "\n",
    "democratic_data_test = democratic_data_clean[democratic_data_clean['state_abbreviation'].isin \\\n",
    "                                (['IN','WV','OR','CA','MT','NJ','NM','ND','SD','PA','RI','CT','DE','MD','KY'])]\n",
    "\n",
    "democratic_data_train = democratic_data_clean[~ democratic_data_clean['state_abbreviation'].isin \\\n",
    "                                (['IN','WV','OR','CA','MT','NJ','NM','ND','SD','PA','RI','CT','DE','MD','KY'])]\n",
    "\n",
    "###create X and y for train and test data. \n",
    "\n",
    "# now that we do not need the fips and state abbriviations any more, only keep \n",
    "# the numeric values and remove 'fips'.\n",
    "X_train_dem = democratic_data_train._get_numeric_data()\n",
    "\n",
    "X_train_dem.drop(['fips'], axis=1, inplace=True)\n",
    "\n",
    "y_train_dem = democratic_data_train['democratic_winner']\n",
    "\n",
    "\n",
    "# same for test data \n",
    "X_TEST_dem = democratic_data_test._get_numeric_data()\n",
    "\n",
    "X_TEST_dem.drop(['fips'], axis=1, inplace=True)\n",
    "\n",
    "y_TEST_dem = democratic_data_test['democratic_winner']\n",
    "\n",
    "\n",
    "# now shuffle them so that future partitioning is certainly random: seed = 123\n",
    "X_train_dem, y_train_dem = shuffle(X_train_dem, y_train_dem, random_state = 123)\n",
    "\n",
    "X_TEST_dem, y_TEST_dem = shuffle(X_TEST_dem, y_TEST_dem, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Republican train / test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a dictionary with fips (unique country code) as key and as values and loop over \n",
    "# the result data for each candidate. In the first loop the percentage of votes for \n",
    "# the first canditate will fill all values of the dict. But in the following loops\n",
    "# the value will be upgraded by if the other candidate had a higher percentage of the vote \n",
    "\n",
    "\n",
    "# 'John Kasich', 'Rand Paul', 'Donald Trump', 'Carly Fiorina', 'Rick Santorum', 'Ted Cruz', 'Jeb Bush', \n",
    "# 'Mike Huckabee', 'Ben Carson', 'Marco Rubio', 'Chris Christie'}\n",
    "\n",
    "\n",
    "rep_winners = {}\n",
    "rep_winners_fips_missing = {}\n",
    "\n",
    "\n",
    "for index, row in republican_results.iterrows():\n",
    "    \n",
    "    if pd.isnull(row['fips']) and row['candidate'] == 'Donald Trump':\n",
    "        \n",
    "        rep_winners_fips_missing[row['county']] = [row['state_abbreviation'], row['fraction_votes'],\n",
    "                                                   'Donald Trump']\n",
    "    \n",
    "    elif row['candidate'] == 'Donald Trump':\n",
    "        rep_winners[row['fips']] = ['Donald Trump', row['fraction_votes']]\n",
    "        \n",
    "\n",
    "# now check for the counties where fips are missing, who are all in new Hampshire, if \n",
    "# an other candite scored higher then Trump\n",
    "\n",
    "for index, row in republican_results.iterrows():\n",
    "    \n",
    "    if pd.isnull(row['fips']):\n",
    "    \n",
    "        if row['candidate'] == 'Rand Paul' and row['fraction_votes'] > rep_winners_fips_missing[row['county']][1]:\n",
    "            rep_winners_fips_missing[row['county']] = [row['state_abbreviation'],row['fraction_votes'], 'Rand Paul']\n",
    "\n",
    "        elif row['candidate'] == 'John Kasich' and row['fraction_votes'] > rep_winners_fips_missing[row['county']][1]:\n",
    "            rep_winners_fips_missing[row['county']] = [row['state_abbreviation'],row['fraction_votes'], 'John Kasich']\n",
    "\n",
    "        elif row['candidate'] == 'Carly Fiorina' and row['fraction_votes'] > rep_winners_fips_missing[row['county']][1]:\n",
    "            rep_winners_fips_missing[row['county']] = [row['state_abbreviation'],row['fraction_votes'], 'Carly Fiorina']\n",
    "\n",
    "        elif row['candidate'] == 'Rick Santorum' and row['fraction_votes'] > rep_winners_fips_missing[row['county']][1]:\n",
    "            rep_winners_fips_missing[row['county']] = [row['state_abbreviation'],row['fraction_votes'], 'Rick Santorum']\n",
    "\n",
    "        elif row['candidate'] == 'Ted Cruz' and row['fraction_votes'] > rep_winners_fips_missing[row['county']][1]:\n",
    "            rep_winners_fips_missing[row['county']] = [row['state_abbreviation'],row['fraction_votes'], 'Ted Cruz']\n",
    "\n",
    "        elif row['candidate'] == 'Jeb Bush' and row['fraction_votes'] > rep_winners_fips_missing[row['county']][1]:\n",
    "            rep_winners_fips_missing[row['county']] = [row['state_abbreviation'],row['fraction_votes'], 'Jeb Bush']\n",
    "            \n",
    "        elif row['candidate'] == 'Mike Huckabee' and row['fraction_votes'] > rep_winners_fips_missing[row['county']][1]:\n",
    "            rep_winners_fips_missing[row['county']] = [row['state_abbreviation'],row['fraction_votes'], 'Mike Huckabee']\n",
    "\n",
    "        elif row['candidate'] == 'Ben Carson'and row['fraction_votes'] > rep_winners_fips_missing[row['county']][1]:\n",
    "            rep_winners_fips_missing[row['county']] = [row['state_abbreviation'],row['fraction_votes'], 'Ben Carson']\n",
    "                                                                                                  \n",
    "        elif row['candidate'] == 'Marco Rubio' and row['fraction_votes'] > rep_winners_fips_missing[row['county']][1]:\n",
    "            rep_winners_fips_missing[row['county']] = [row['state_abbreviation'],row['fraction_votes'], 'Marco Rubio']\n",
    "\n",
    "        elif row['candidate'] == 'Chris Christie' and row['fraction_votes'] > rep_winners_fips_missing[row['county']][1]:\n",
    "            rep_winners_fips_missing[row['county']] = [row['state_abbreviation'],row['fraction_votes'], 'Chris Christie']\n",
    "\n",
    "# now check for all the rows where fips are present:\n",
    "for index, row in republican_results.iterrows():\n",
    "    \n",
    "    # skip rows where the fip is missing, already did these above.\n",
    "    if pd.isnull(row['fips']):\n",
    "        continue \n",
    "    \n",
    "    elif row['candidate'] == 'Rand Paul' and row['fraction_votes'] > rep_winners[row['fips']][1]:\n",
    "        rep_winners[row['fips']] = ['Rand Paul', row['fraction_votes']]\n",
    "    \n",
    "    elif row['candidate'] == 'John Kasich' and row['fraction_votes'] > rep_winners[row['fips']][1]:\n",
    "        rep_winners[row['fips']] = ['John Kasich', row['fraction_votes']]\n",
    "    \n",
    "    elif row['candidate'] == 'Carly Fiorina' and row['fraction_votes'] > rep_winners[row['fips']][1]:\n",
    "        rep_winners[row['fips']] = ['Carly Fiorina', row['fraction_votes']]\n",
    "        \n",
    "    elif row['candidate'] == 'Rick Santorum' and row['fraction_votes'] > rep_winners[row['fips']][1]:\n",
    "        rep_winners[row['fips']] = ['Rick Santorum', row['fraction_votes']]\n",
    "        \n",
    "    elif row['candidate'] == 'Ted Cruz' and row['fraction_votes'] > rep_winners[row['fips']][1]:\n",
    "        rep_winners[row['fips']] = ['Ted Cruz', row['fraction_votes']]\n",
    "        \n",
    "    elif row['candidate'] == 'Jeb Bush' and row['fraction_votes'] > rep_winners[row['fips']][1]:\n",
    "        rep_winners[row['fips']] = ['Jeb Bush', row['fraction_votes']]\n",
    "        \n",
    "    elif row['candidate'] == 'Mike Huckabee' and row['fraction_votes'] > rep_winners[row['fips']][1]:\n",
    "        rep_winners[row['fips']] = ['Mike Huckabee', row['fraction_votes']]\n",
    "        \n",
    "    elif row['candidate'] == 'Ben Carson'and row['fraction_votes'] > rep_winners[row['fips']][1]:\n",
    "        rep_winners[row['fips']] = ['Ben Carson', row['fraction_votes']]\n",
    "    \n",
    "    elif row['candidate'] == 'Marco Rubio' and row['fraction_votes'] > rep_winners[row['fips']][1]:\n",
    "        rep_winners[row['fips']] = ['Marco Rubio', row['fraction_votes']]\n",
    "    \n",
    "    elif row['candidate'] == 'Chris Christie' and row['fraction_votes'] > rep_winners[row['fips']][1]:\n",
    "        rep_winners[row['fips']] = ['Chris Christie', row['fraction_votes']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now check for all the rows where fips are present:\n",
    "\n",
    "for index, row in republican_results.iterrows():\n",
    "    \n",
    "    # skip rows where the fip is missing, already did these above.\n",
    "    if pd.isnull(row['fips']):\n",
    "        continue \n",
    "    \n",
    "    elif row['candidate'] == 'Rand Paul' and row['fraction_votes'] > rep_winners[row['fips']][1]:\n",
    "        rep_winners[row['fips']] = ['Rand Paul', row['fraction_votes']]\n",
    "    \n",
    "    elif row['candidate'] == 'John Kasich' and row['fraction_votes'] > rep_winners[row['fips']][1]:\n",
    "        rep_winners[row['fips']] = ['John Kasich', row['fraction_votes']]\n",
    "    \n",
    "    elif row['candidate'] == 'Carly Fiorina' and row['fraction_votes'] > rep_winners[row['fips']][1]:\n",
    "        rep_winners[row['fips']] = ['Carly Fiorina', row['fraction_votes']]\n",
    "        \n",
    "    elif row['candidate'] == 'Rick Santorum' and row['fraction_votes'] > rep_winners[row['fips']][1]:\n",
    "        rep_winners[row['fips']] = ['Rick Santorum', row['fraction_votes']]\n",
    "        \n",
    "    elif row['candidate'] == 'Ted Cruz' and row['fraction_votes'] > rep_winners[row['fips']][1]:\n",
    "        rep_winners[row['fips']] = ['Ted Cruz', row['fraction_votes']]\n",
    "        \n",
    "    elif row['candidate'] == 'Jeb Bush' and row['fraction_votes'] > rep_winners[row['fips']][1]:\n",
    "        rep_winners[row['fips']] = ['Jeb Bush', row['fraction_votes']]\n",
    "        \n",
    "    elif row['candidate'] == 'Mike Huckabee' and row['fraction_votes'] > rep_winners[row['fips']][1]:\n",
    "        rep_winners[row['fips']] = ['Mike Huckabee', row['fraction_votes']]\n",
    "        \n",
    "    elif row['candidate'] == 'Ben Carson'and row['fraction_votes'] > rep_winners[row['fips']][1]:\n",
    "        rep_winners[row['fips']] = ['Ben Carson', row['fraction_votes']]\n",
    "    \n",
    "    elif row['candidate'] == 'Marco Rubio' and row['fraction_votes'] > rep_winners[row['fips']][1]:\n",
    "        rep_winners[row['fips']] = ['Marco Rubio', row['fraction_votes']]\n",
    "    \n",
    "    elif row['candidate'] == 'Chris Christie' and row['fraction_votes'] > rep_winners[row['fips']][1]:\n",
    "        rep_winners[row['fips']] = ['Chris Christie', row['fraction_votes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\development\\anaconda\\lib\\site-packages\\pandas\\core\\indexes\\api.py:77: RuntimeWarning: '<' not supported between instances of 'str' and 'int', sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    }
   ],
   "source": [
    "# create the y column: 'republican_winner'. Set values to 0 for now. Merge with the county data.\n",
    "\n",
    "republican_winner = {'republican_winner' : [0] * len(county_data['fips'])}\n",
    "\n",
    "republican_winner_df = pd.DataFrame(data = republican_winner)\n",
    "\n",
    "republican_data = pd.concat([county_data ,republican_winner_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now set the values of the 'republican_winner' column to winner. Value stays 0 if \n",
    "# the county code is not in the result data-set, and therefore missing\n",
    "\n",
    "for index, row in republican_data.iterrows():\n",
    "    \n",
    "    # this is the if statement for where country fip is missing and berny is thus the winner. \n",
    "    if pd.isnull(row['fips']): \n",
    "        if row['area_name'] in rep_winners_fips_missing:\n",
    "            republican_data.loc[index, 'republican_winner'] = 'Donald Trump'\n",
    "    \n",
    "    # otherwise look in the winner dict to see who was the winner\n",
    "    elif row['fips'] in rep_winners:\n",
    "        republican_data.loc[index, 'republican_winner'] = rep_winners[row['fips']][0]\n",
    "    \n",
    "\n",
    "# remove all the rows where the y variable is missing : value 0\n",
    "republican_data_clean = republican_data[republican_data['republican_winner'].isin \\\n",
    "                                        (['John Kasich', 'Rand Paul', 'Donald Trump', \n",
    "                                        'Carly Fiorina', 'Rick Santorum', 'Ted Cruz', 'Jeb Bush', \n",
    "                                        'Mike Huckabee', 'Ben Carson', 'Marco Rubio', 'Chris Christie'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create train/ test split \n",
    "\n",
    "republican_data_test = republican_data_clean[republican_data_clean['state_abbreviation'].isin \\\n",
    "                                (['IN','WV','OR','CA','MT','NJ','NM','ND','SD','PA','RI','CT','DE','MD','NE'])]\n",
    "\n",
    "republican_data_train = republican_data_clean[~ republican_data_clean['state_abbreviation'].isin \\\n",
    "                                (['IN','WV','OR','CA','MT','NJ','NM','ND','SD','PA','RI','CT','DE','MD','NE'])]\n",
    "\n",
    "######\n",
    "###### create X and y for train and test data. \n",
    "######\n",
    "\n",
    "# now that we do not need the fips and state abbriviations any more, only keep \n",
    "# the numeric values and remove 'fips'.\n",
    "X_train_rep = republican_data_train._get_numeric_data()\n",
    "\n",
    "X_train_rep.drop(['fips'], axis=1, inplace=True)\n",
    "\n",
    "y_train_rep = republican_data_train['republican_winner']\n",
    "\n",
    "\n",
    "# same for test data \n",
    "X_TEST_rep = republican_data_test._get_numeric_data()\n",
    "\n",
    "X_TEST_rep.drop(['fips'], axis=1, inplace=True)\n",
    "\n",
    "y_TEST_rep = republican_data_test['republican_winner']\n",
    "\n",
    "\n",
    "# now shuffle them so that future partitioning is certainly random: seed = 123\n",
    "X_train_rep, y_train_rep = shuffle(X_train_rep, y_train_rep, random_state = 123)\n",
    "\n",
    "X_TEST_rep, y_TEST_rep = shuffle(X_TEST_rep, y_TEST_rep, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most_Votes train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\development\\anaconda\\lib\\site-packages\\pandas\\core\\indexes\\api.py:77: RuntimeWarning: '<' not supported between instances of 'str' and 'int', sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary with fips (unique county codes) as keys and another dict as values.\n",
    "# this second dict contains party as keys and their votes in a list as values.\n",
    "\n",
    "# Also create the same dict for counties which do not have a fib.\n",
    "\n",
    "most_votes_dict = {}\n",
    "\n",
    "most_votes_dict_fips_missing = {}\n",
    "\n",
    "# first for rows where fips are present:\n",
    "for index, row in results_data.iterrows():\n",
    "    \n",
    "    if not pd.isnull(row['fips']):\n",
    "        \n",
    "        if row['fips'] not in most_votes_dict:\n",
    "            \n",
    "            most_votes_dict[row['fips']] = {'Democrats': 0, 'Republicans': 0}\n",
    "\n",
    "            \n",
    "for index, row in results_data.iterrows():\n",
    "    \n",
    "    if not pd.isnull(row['fips']) and row['fips'] in most_votes_dict:\n",
    "            \n",
    "            if row['party'] == 'Democrat':\n",
    "                most_votes_dict[row['fips']]['Democrats'] += row['votes']\n",
    "                \n",
    "            elif row['party'] == 'Republican':\n",
    "                most_votes_dict[row['fips']]['Republicans'] += row['votes']\n",
    "\n",
    "\n",
    "                \n",
    "# now for the rows where fip is missing:\n",
    "for index, row in results_data.iterrows():    \n",
    "    \n",
    "    if pd.isnull(row['fips']):\n",
    "        \n",
    "        if row['county'] not in most_votes_dict_fips_missing:\n",
    "            most_votes_dict_fips_missing[row['county']] = {'Democrats': 0, 'Republicans': 0}\n",
    "\n",
    "for index, row in results_data.iterrows():    \n",
    "    \n",
    "    if pd.isnull(row['fips']) and row['county'] in most_votes_dict_fips_missing:\n",
    "            \n",
    "        if row['party'] == 'Democrat':\n",
    "            most_votes_dict_fips_missing[row['county']]['Democrats'] += row['votes']\n",
    "                \n",
    "        elif row['party'] == 'Republican':\n",
    "            most_votes_dict_fips_missing[row['county']]['Republicans'] += row['votes']\n",
    "            \n",
    "\n",
    "most_votes = {'most_votes' : [0] * len(county_data['fips'])}\n",
    "\n",
    "most_votes_df = pd.DataFrame(data = most_votes)\n",
    "\n",
    "votes_data = pd.concat([county_data ,most_votes_df], axis = 1)\n",
    "\n",
    "# now set the y values to the party with the most votes. Value stays 0 if \n",
    "# the county code is not in the result data-set, and therefore missing\n",
    "\n",
    "for index, row in votes_data.iterrows():\n",
    "    \n",
    "    # this is the if statement for where country fip is missing and berny is thus the winner. \n",
    "    if pd.isnull(row['fips']): \n",
    "        \n",
    "        if row['area_name'] in most_votes_dict_fips_missing:\n",
    "            \n",
    "            winner = None \n",
    "            \n",
    "            if most_votes_dict_fips_missing[row['area_name']]['Republicans'] > \\\n",
    "                most_votes_dict_fips_missing[row['area_name']]['Democrats']:\n",
    "                winner = 'Republicans'\n",
    "            \n",
    "            elif most_votes_dict_fips_missing[row['area_name']]['Democrats'] > \\\n",
    "                most_votes_dict_fips_missing[row['area_name']]['Republicans']:\n",
    "                winner = 'Democrats'\n",
    "            \n",
    "            votes_data.loc[index, 'most_votes'] = winner \n",
    "    \n",
    "    # otherwise look in the winner dict to see who was the winner\n",
    "    elif row['fips'] in most_votes_dict:\n",
    "        \n",
    "            winner = None \n",
    "            \n",
    "            if most_votes_dict[row['fips']]['Republicans'] > most_votes_dict[row['fips']]['Democrats']:\n",
    "                winner = 'Republicans'\n",
    "            \n",
    "            elif most_votes_dict[row['fips']]['Democrats'] > most_votes_dict[row['fips']]['Republicans']:\n",
    "                winner = 'Democrats'\n",
    "    \n",
    "            votes_data.loc[index, 'most_votes'] = winner\n",
    "\n",
    "        \n",
    "    \n",
    "# remove all the rows where the y variable is missing : value 0\n",
    "votes_data_clean = votes_data[votes_data['most_votes'].isin \\\n",
    "                                        (['Republicans', 'Democrats'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create train/test split \n",
    "\n",
    "votes_data_test = votes_data_clean[votes_data_clean['state_abbreviation'].isin \\\n",
    "                                (['IN','WV','OR','CA','MT','NJ','NM','ND','SD','PA','RI','CT','DE','MD','KY'])]\n",
    "\n",
    "votes_data_train = votes_data_clean[~ votes_data_clean['state_abbreviation'].isin \\\n",
    "                                (['IN','WV','OR','CA','MT','NJ','NM','ND','SD','PA','RI','CT','DE','MD','KY'])]\n",
    "\n",
    "######\n",
    "###### create X and y for train and test data. \n",
    "######\n",
    "\n",
    "# now that we do not need the fips and state abbriviations any more, only keep \n",
    "# the numeric values and remove 'fips'.\n",
    "X_train_votes = votes_data_train._get_numeric_data()\n",
    "\n",
    "X_train_votes.drop(['fips'], axis=1, inplace=True)\n",
    "\n",
    "y_train_votes = votes_data_train['most_votes']\n",
    "\n",
    "\n",
    "# same for test data \n",
    "X_TEST_votes = votes_data_test._get_numeric_data()\n",
    "\n",
    "X_TEST_votes.drop(['fips'], axis=1, inplace=True)\n",
    "\n",
    "y_TEST_votes = votes_data_test['most_votes']\n",
    "\n",
    "\n",
    "# now shuffle them so that future partitioning is certainly random: seed = 123\n",
    "X_train_votes, y_train_votes = shuffle(X_train_votes, y_train_votes, random_state = 123)\n",
    "\n",
    "X_TEST_votes, y_TEST_votes = shuffle(X_TEST_votes, y_TEST_votes, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Models: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best performance: 0.923\n",
      "The corresponding regularization parameter C is: 8.377\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "logreg_pipe1 = make_pipeline(PolynomialFeatures(),MinMaxScaler(), LogisticRegression(random_state=123))\n",
    "param_grid1 = {'logisticregression__C': np.logspace(-6,3,14)}\n",
    "grid1 = GridSearchCV(logreg_pipe1, param_grid1, cv=5)\n",
    "grid1.fit(X_train_votes, y_train_votes)\n",
    "print(\"The best performance: {:.3f}\".format(grid1.score(X_train_votes, y_train_votes)))\n",
    "print(\"The corresponding regularization parameter C is: {:.3f}\".format(grid1.best_params_['logisticregression__C']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.651347068146\n"
     ]
    }
   ],
   "source": [
    "print(grid1.score(X_TEST_votes, y_TEST_votes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Democrats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best performance: 0.903\n",
      "The corresponding regularization parameter C is: 41.246\n"
     ]
    }
   ],
   "source": [
    "logreg_pipe2 = make_pipeline(PolynomialFeatures(),MinMaxScaler(), LogisticRegression(random_state=123))\n",
    "param_grid2 = {'logisticregression__C': np.logspace(-6,3,14)}\n",
    "grid2 = GridSearchCV(logreg_pipe2, param_grid2, cv=5)\n",
    "grid2.fit(X_train_dem, y_train_dem)\n",
    "print(\"The best performance: {:.3f}\".format(grid2.score(X_train_dem, y_train_dem)))\n",
    "print(\"The corresponding regularization parameter C is: {:.3f}\".format(grid2.best_params_['logisticregression__C']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.522364217252\n"
     ]
    }
   ],
   "source": [
    "print(grid2.score(X_TEST_dem, y_TEST_dem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Republicans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best performance: 0.867\n",
      "The corresponding regularization parameter C is: 8.377\n"
     ]
    }
   ],
   "source": [
    "logreg_pipe3 = make_pipeline(PolynomialFeatures(),MinMaxScaler(), LogisticRegression(random_state=123))\n",
    "param_grid3 = {'logisticregression__C': np.logspace(-6,3,14)}\n",
    "grid3 = GridSearchCV(logreg_pipe3, param_grid3, cv=5)\n",
    "grid3.fit(X_train_rep, y_train_rep)\n",
    "print(\"The best performance: {:.3f}\".format(grid3.score(X_train_rep, y_train_rep)))\n",
    "print(\"The corresponding regularization parameter C is: {:.3f}\".format(grid3.best_params_['logisticregression__C']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.699834162521\n"
     ]
    }
   ],
   "source": [
    "print(grid3.score(X_TEST_rep, y_TEST_rep))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
